for (i in 1:length(return)) {
if(return[i]>0){Up_Down[i]<-"Up"
}else if(Up_Down[i]<0){Up_Down[i]<-"Up"
}else(Up_Down[i]==0){Up_Down[i]<-"stationary"
for (i in 1:length(return)) {
if(return[i]>0){Up_Down[i]<-"Up"
}else if(Up_Down[i]<0){Up_Down[i]<-"down"
}else(Up_Down[i]==0){Up_Down[i]<-"stationary"
for (i in 1:length(return)) {
if(return[i]>0){Up_Down[i]<-"Up"
}
else(Up_Down[i]==0){Up_Down[i]<-"stationary"
Up_Down<-NULL
for (i in 1:length(return)) {
if(return[i]>0){Up_Down[i]<-"Up"
}
else if(Up_Down[i]<0){Up_Down[i]<-"down"
}
else(Up_Down[i]==0){Up_Down[i]<-"stationary"
for (i in 1:length(return)) {
if(return[i]>0){Up_Down[i]<-"Up"
}
else if(Up_Down[i]<0){Up_Down[i]<-"down"
}
else(Up_Down[i]==0){Up_Down[i]<-"stationary"
Up_Down<-NULL
for (i in 1:length(return)) {
if(return[i]>0){Up_Down[i]<-'Up'
}
else if(Up_Down[i]<0){Up_Down[i]<-'down'
}
else(Up_Down[i]==0){Up_Down[i]<-'stationary'
for (i in 1:length(return)) {
if(return[i]>0){Up_Down[i]<-'Up'}
else if(Up_Down[i]<0){Up_Down[i]<-'down'}
else(Up_Down[i]==0){Up_Down[i]<-'stationary'
for (i in 1:length(return)) {
if(return[i]>0){Up_Down[i]<-"Up"}
else if(Up_Down[i]<0){Up_Down[i]<-"down"}
else(Up_Down[i]==0){Up_Down[i]<-"stationary"
for (i in 1:length(return)) {
if(return[i]>0){Up_Down[i]<-"Up"}
else if(Up_Down[i]<0){Up_Down[i]<-"down"}
else(Up_Down[i]==0) Up_Down[i]<-"stationary"
for (i in 1:length(return)) {
if(return[i]>0){Up_Down[i]<-"Up"}
}
for (i in 1:length(return)) {
if(return[i]>0==TRUE){Up_Down[i]<-"Up"}
return[1]>0
return
dim(sp500)
length(return)
return<-return[-1]
for (i in 1:length(return)) {
if(return[i]>0){Up_Down[i]<-"Up"}
else if(Up_Down[i]<0){Up_Down[i]<-"down"}
else(Up_Down[i]==0){Up_Down[i]<-"stationary"
for (i in 1:length(return)) {
if(return[i]>0){Up_Down[i]<-"Up"}
}
}
for (i in 1:length(return)) {
if(return[i]>0){Up_Down[i]<-"Up"}
}
for (i in 1:length(return)) {
if(return[i]>0){Up_Down[i]<-"Up"}
else if(Up_Down[i]<0){Up_Down[i]<-"down"}
else(Up_Down[i]==0){Up_Down[i]<-"stationary"}
for (i in 1:length(return)) {
if(Up_Down[i]==0){Up_Down[i]<-"stationary"
}
for (i in 1:length(return)) {
if(Up_Down[i]<0){Up_Down[i]<-"down"}
}
Up_Down
}
Up_Down
return<-NULL
for (i in 2:length(sp500[,1])) {
return[i]<-(sp500[i,1]-sp500[i-1,1])/sp500[i-1,1]
}
return<-return[-1]
for (i in 1:length(return)) {
if(return[i]>0){Up_Down[i]<-"Up"}
else if(Up_Down[i]<0){Up_Down[i]<-"down"}
else(Up_Down[i]==0){Up_Down[i]<-"stationary"}
for (i in 1:length(return)) {
if(return[i]>0) {Up_Down[i]<-"Up"}
else if(Up_Down[i]<0) {Up_Down[i]<-"down"}
else(Up_Down[i]==0) {Up_Down[i]<-"stationary"}
for (i in 1:length(return)) {
if(return[i]>0) {Up_Down[i]<-"Up"}
else(Up_Down[i]<0) {Up_Down[i]<-"down"}
for (i in 1:length(return)) {
if(return[i]>0) {Up_Down[i]<-"Up"}
else if(Up_Down[i]<0) {Up_Down[i]<-"down"}
else{Up_Down[i]<-"stationary"}
}
return
for (i in 1:length(return)) {
if(return[i]>0) {Up_Down[i]<-"Up"}
else if(Up_Down[i]<0) {Up_Down[i]<-"down"}
else {Up_Down[i]<-"stationary"}
}
sum(is.na(return))
for (i in 1:length(return)) {
if(return[i]>0) {Up_Down[i]<-"Up"}
else if(Up_Down[i]<0) {Up_Down[i]<-"down"}
else {Up_Down[i]<-"stationary"}
}
Up_Down
Up_Down<-NULL
for (i in 1:length(return)) {
if(return[i]>0) {Up_Down[i]<-"Up"}
else if(Up_Down[i]<0) {Up_Down[i]<-"down"}
else {Up_Down[i]<-"stationary"}
}
Up_Down
for (i in 1:length(return)) {
if(return[i]>0) {Up_Down[i]<-"Up"}
else if(return[i]>0) {Up_Down[i]<-"down"}
else {return[i]<-"stationary"}
}
Up_Down
return<-NULL
for (i in 2:length(sp500[,1])) {
return[i]<-(sp500[i,1]-sp500[i-1,1])/sp500[i-1,1]
}
zero_check<-NULL
for (i in 1:length(return)) {
zero_check[i]<-ifelse(return[i]==0,TRUE,FALSE)
}
sum(zero_check[-1])
Up_Down<-NULL
return<-return[-1]
for (i in 1:length(return)) {
if(return[i]>0) {Up_Down[i]<-"Up"}
else if(return[i]<0) {Up_Down[i]<-"down"}
else {Up_Down[i]<-"stationary"}
}
Up_Down
sp500_new<-cbind(sp500[-1,],return,Up_Down)
head(sp500_new)
dim(sp500_new)
sp500_new[,2:9]<-scale(sp500_new[,2:9],center=T,scale=T)
sp500_new
library(princomp)
test.pr<-princomp(sp500_new[,2:9],cor=TRUE)
summary(test.pr,loadings=TRUE)
screeplot(test.pr,type="lines")
head(test.pr)
data<-cbind(test.pr_new,sp500_new[,c(1,10,11)])
test.pr_new<-test.pr[,1:4]
dim(test.pr)
test.pr<-princomp(sp500_new[,2:9],cor=TRUE)
test.pr_new<-test.pr[,1:4]
test.pr
test.pr_new<-test.pr$scores[,1:4]
data<-cbind(test.pr_new,sp500_new[,c(1,10,11)])
head(data)
install.packages("randomForest")
library(randomForest)
dim(data)
dim(data)[1]
runif(dim(data)[1]-6000,1,dim(data)[1])
round(6404,0)
round(runif(dim(data)[1]-6000,1,dim(data)[1]),0)
test<-data[round(runif(dim(data)[1]-6000,1,dim(data)[1]),0),]
test
train<-data[-round(runif(dim(data)[1]-6000,1,dim(data)[1]),0),]
train_rf<-train[,-c(5,6)]
test_rf<-test[,-c(5,6)]
train_rf
n<-length(name(train_rf))
n<-length(names(train_rf))
n<-length(names(train_rf))
rate=1
for (i in 1:(n-1)){
set.seed(1000)
rf_train<-randomForest(as.factor(train_rf$Up_Down)~.,data=train_rf,mtry=i,ntree=1000)
rate[i]<-mean( rf_train$err.rate)
print(rf_train)
}
rate
plot(rate)
rf_train<-randomForest(as.factor(train_rf$Up_Down)~.,data=train_rf,mtry=3,ntree=1000)
plot(rf_train)
rf_train<-randomForest(as.factor(train_rf$Up_Down)~.,data=train_rf,mtry=3,ntree=400)
importance(rf_train,type=1)
importance(rf_train,type=2)
print(rf_train)
hist(treesize(rf_train))
pred<-predict(rf_train,newdata=test_rf)
pred
length(pred)
pred_out_1<-predict(object=rf_train,newdata=test_rf,type="prob")
pred_out_1
table <- table(pred,test_rf$Up_Down)
table
sum(diag(table))/sum(table)
diag(table)
sum(diag(table))/sum(table))
plot(margin(rf_train,test_rf$Up_Down))
test_rf$Up_Down[1]
test_rf$Up_Down[1]=="Up"
Check[1]<-pred[1]==test_rf$Up_Down[1]
Check<-NULL
Check[1]<-pred[1]==test_rf$Up_Down[1]
Check
Check<-NULL
for (i in 1:length(pred)) {
Check[i]<-pred[i]==test_rf$Up_Down[i]
}
check
Check
sum(Check)
sum
sum(Check)/length(pred)
library(e1071)
train
train_svm<-train[,-c(5,7)]
test_svm<-test[,-c(5,7)]
svm.fit<-svm(train_svm$return~.,data=train_svm)
summary(svm.fit)
pred<-predict(svm.fit)
pred
train$Up_Down
for (i in 1:length(pred)) {
if(pred[i]>0){pred[i]<-"Up"}
else if(pred[i]==0){pred[i]<-"Stationary"}
else(pred[i]<0){pred[i]<-"down"}
pred_New<-NULL
for (i in 1:length(pred)) {
if(pred[i]>0){pred_New[i]<-"Up"}
else if(pred[i]==0){pred_New[i]<-"Stationary"}
else(pred[i]<0){pred_New[i]<-"down"}
for (i in 1:length(return)) {
if(return[i]>0) {Up_Down[i]<-"Up"}
else if(return[i]<0) {Up_Down[i]<-"down"}
else {Up_Down[i]<-"stationary"}
}
for (i in 1:length(pred)) {
if(pred[i]>0) {pred_New[i]<-"Up"}
else if(pred[i]<0) {pred_New[i]<-"down"}
else {Up_Down[i]<-"stationary"}
}
pred_New
table <- table(pred_New,test_svm$Up_Down)
test_svm$Up_Down
test_svm
table <- table(pred_New,test$Up_Down)
test$Up_Down
pred_New
length(pred_New)
length(test$Up_Down)
pred<-predict(svm.fit,newdata = test_svm)
pred_New<-NULL
for (i in 1:length(pred)) {
if(pred[i]>0) {pred_New[i]<-"Up"}
else if(pred[i]<0) {pred_New[i]<-"down"}
else {Up_Down[i]<-"stationary"}
}
table <- table(pred_New,test$Up_Down)
sum(diag(table))/sum(table)
library(xgboost)
install.packages("xgboost")
xgb <- xgboost(data = data.matrix(X[,-1]),
label = y,
eta = 0.1,
max_depth = 15,
nround=25,
subsample = 0.5,
colsample_bytree = 0.5,
seed = 1,
eval_metric = "merror",
objective = "multi:softprob",
num_class = 3,
nthread = 3
)
library(xgboost)
xgb <- xgboost(data = data.matrix(X[,-1]),
label = y,
eta = 0.1,
max_depth = 15,
nround=25,
subsample = 0.5,
colsample_bytree = 0.5,
seed = 1,
eval_metric = "merror",
objective = "multi:softprob",
num_class = 3,
nthread = 3
)
train_xgb<-train[,-c(5,6)]
test_xgb<-test[,-c(5,6)]
head(train_xgb)
xgb <- xgboost(data = train_xgb[,-5],
label = y,
eta = 0.1,
max_depth = 15,
nround=25,
subsample = 0.5,
colsample_bytree = 0.5,
seed = 1,
eval_metric = "merror",
objective = "multi:softprob",
num_class = 3,
nthread = 3
)
xgb <- xgboost(data = train_xgb[,-5],
label = train_xgb[,5],
eta = 0.1,
max_depth = 15,
nround=25,
subsample = 0.5,
colsample_bytree = 0.5,
seed = 1,
eval_metric = "merror",
objective = "multi:softprob",
num_class = 3,
nthread = 3
)
train_xgb<-as.matrix(train[,-c(5,6)])
test_xgb<-as.matrix(test[,-c(5,6)])
xgb <- xgboost(data = train_xgb[,-5],
label = train_xgb[,5],
eta = 0.1,
max_depth = 15,
nround=25,
subsample = 0.5,
colsample_bytree = 0.5,
seed = 1,
eval_metric = "merror",
objective = "multi:softprob",
num_class = 3,
nthread = 3
)
train_svm<-as.matrix(train[,-c(5,7)])
test_svm<-as.matrix(test[,-c(5,7)])
train_svm
train_xgb<-as.matrix(train[,-c(5,7)])
test_xgb<-as.matrix(test[,-c(5,7)])
xgb <- xgboost(data = train_xgb[,-5],
label = train_xgb[,5],
eta = 0.1,
max_depth = 15,
nround=25,
subsample = 0.5,
colsample_bytree = 0.5,
seed = 1,
eval_metric = "merror",
objective = "multi:softprob",
num_class = 3,
nthread = 3
)
xgb <- xgboost(data = train_xgb[,-5],
label = train_xgb[,5]
)
xgb <- xgboost(data = train_xgb[,-5],
label = train_xgb[,5],
eta = 0.3,
max_depth = 15,
nround=25,
subsample = 0.5,
colsample_bytree = 0.5,
seed = 1,
eval_metric = "merror",
objective = "multi:softprob",
num_class = 3,
nthread = 3
)
test_xgb<-as.matrix(test[,-c(5,7)])
xgb <- xgboost(data = train_xgb[,-5],
label = train_xgb[,5],
eta = 0.3,
max_depth = 15,
nround=25,
subsample = 0.5,
colsample_bytree = 0.5,
seed = 1,
eval_metric = "merror",
objective = "multi:softprob",
nthread = 3
)
xgb <- xgboost(data = train_xgb[,-5],
label = train_xgb[,5],
eta = 0.3,
max_depth = 15,
nround=25,
subsample = 0.5,
colsample_bytree = 0.5,
seed = 1,
eval_metric = "merror",
objective = "multi:softprob",
num_class = 12,
nthread = 3
)
library(gbm)
install.packages("gbm")
library(gbm)
train_gbm<-train[,-c(5,7)]
test_gbm<-test[,-c(5,7)]
train_gbm
gbm <-  gbm(formula = return ~ .,distribution = "gaussian",data = trainset,n.trees = 1000,interaction.depth = 7,shrinkage = 0.01,cv.folds = 5)
gbm <-  gbm(formula = return ~ .,distribution = "gaussian",data = train_gbm,n.trees = 1000,interaction.depth = 7,shrinkage = 0.01,cv.folds = 5)
summary(gbm)
iter = gbm.perf(churn.gbm,method = "cv")
iter = gbm.perf(gbm,method = "cv")
iter
train_gbm,n.trees = 1000,interaction.depth = 7,shrinkage = 0.01)
gbm <-  gbm(formula = return ~ .,distribution = "gaussian",data = train_gbm,n.trees = 1000,interaction.depth = 7,shrinkage = 0.01)
summary(gbm)
iter = gbm.perf(gbm,method = "cv")
gbm <-  gbm(formula = return ~ .,distribution = "gaussian",data = train_gbm,n.trees = 1000,interaction.depth = 7,shrinkage = 0.01,cv.folds=5)
summary(gbm)
summary(gbm)
iter = gbm.perf(gbm,method = "cv")
iter
gbm <-  gbm(formula = return ~ .,distribution = "gaussian",data = train_gbm,n.trees = 91,interaction.depth = 7,shrinkage = 0.01)
train
train_gbm<-train[,-c(5,6)]
train
train_gbm<-train[,-c(5,6)]
test_gbm<-test[,-c(5,6)]
train_gbm
train_gbm<-train[,-c(5,7)]
test_gbm<-test[,-c(5,7)]
pred<-predict(gbm,newdata = test_gbm)
gbm_model <-  gbm(formula = return ~ .,distribution = "gaussian",data = train_gbm,n.trees = 91,interaction.depth = 7,shrinkage = 0.01)
pred<-predict(gbm,newdata = test_gbm)
pred<-predict(gbm_model,newdata = test_gbm)
gbm_model
predict(gbm_model,newdata = test_gbm)
test_gbm
pred<-predict(gbm_model,newdata = test_gbm[,1:4])
pred<-predict(gbm_model,newdata = test_gbm)
pred<-predict(gbm_model,newdata = test_gbm,n.trees = iter)
pred
test_gbm
for (i in 1:length(pred)) {
if(pred[i]>0) {pred_New[i]<-"Up"}
else if(pred[i]<0) {pred_New[i]<-"down"}
else {Up_Down[i]<-"stationary"}
}
table <- table(pred_New,test$Up_Down)
sum(diag(table))/sum(table)
GBM_accuracy_rate<-sum(diag(table))/sum(table)
#SVM model
train_svm<-train[,-c(5,7)]
test_svm<-test[,-c(5,7)]
svm.fit<-svm(train_svm$return~.,data=train_svm)
summary(svm.fit)
pred<-predict(svm.fit,newdata = test_svm)
pred_New<-NULL
for (i in 1:length(pred)) {
if(pred[i]>0) {pred_New[i]<-"Up"}
else if(pred[i]<0) {pred_New[i]<-"down"}
else {Up_Down[i]<-"stationary"}
}
#test
table <- table(pred_New,test$Up_Down)
SVM_accuracy_rate<-sum(diag(table))/sum(table)
train_rf<-train[,-c(5,6)]
test_rf<-test[,-c(5,6)]
n<-length(names(train_rf))
rate=1
#Find the best mtry
for (i in 1:(n-1)){
set.seed(1000)
rf_train<-randomForest(as.factor(train_rf$Up_Down)~.,data=train_rf,mtry=i,ntree=1000)
rate[i]<-mean( rf_train$err.rate)
print(rf_train)
}
rate
plot(rate)
#Find the best ntree
set.seed(100)
rf_train<-randomForest(as.factor(train_rf$Up_Down)~.,data=train_rf,mtry=3,ntree=1000)
plot(rf_train)
#Build model
set.seed(120)
rf_train<-randomForest(as.factor(train_rf$Up_Down)~.,data=train_rf,mtry=3,ntree=400)
print(rf_train)
#test
pred<-predict(rf_train,newdata=test_rf)
pred_out_1<-predict(object=rf_train,newdata=test_rf,type="prob")
table <- table(pred,test_rf$Up_Down)
sum(diag(table))/sum(table)
#Accuracy rate is too high ??? let's check again
Check<-NULL
for (i in 1:length(pred)) {
Check[i]<-pred[i]==test_rf$Up_Down[i]
}
RF_accuracy_rate<-sum(Check)/length(pred)
#We may overfit,need K-fold CV in the future.
kable(RF_accuracy_rate,SVM_accuracy_rate,GBM_accuracy_rate)
knitr::kable(RF_accuracy_rate,SVM_accuracy_rate,GBM_accuracy_rate)
library(knitr)
knitr::kable(RF_accuracy_rate,SVM_accuracy_rate,GBM_accuracy_rate)
tabe(RF_accuracy_rate,SVM_accuracy_rate,GBM_accuracy_rate)
table(RF_accuracy_rate,SVM_accuracy_rate,GBM_accuracy_rate)
table(RF_accuracy_rate,SVM_accuracy_rate,GBM_accuracy_rate)
matrix(RF_accuracy_rate,SVM_accuracy_rate,GBM_accuracy_rate)
RF_accuracy_rate
table(RF_accuracy_rate,SVM_accuracy_rate,GBM_accuracy_rate)
data.frame(RF_accuracy_rate,SVM_accuracy_rate,GBM_accuracy_rate)
train_gbm<-train[,-c(5,7)]
test_gbm<-test[,-c(5,7)]
iter = gbm.perf(gbm,method = "cv")
plot(rate)
rate
